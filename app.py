import streamlit as st
import pandas as pd
import glob
import os
import html
import re
import math
from datetime import datetime, date


# ==========================
# Tempostar CSV èª­ã¿è¾¼ã¿
# ==========================
@st.cache_data
def load_tempostar_data(file_paths):
    dfs = []
    for path in file_paths:
        df = pd.read_csv(path, encoding="cp932")
        df["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"] = os.path.basename(path)
        dfs.append(df)

    all_df = pd.concat(dfs, ignore_index=True)

    # æ•°å€¤åˆ—ã‚’æ˜ç¤ºçš„ã«å¤‰æ›
    for col in ["å¢—æ¸›å€¤", "å¤‰å‹•å¾Œ"]:
        if col in all_df.columns:
            all_df[col] = (
                pd.to_numeric(all_df[col], errors="coerce")
                .fillna(0)
                .astype(int)
            )

    return all_df


# ==========================
# å•†å“ç”»åƒãƒã‚¹ã‚¿èª­ã¿è¾¼ã¿
# ==========================
@st.cache_data
def load_image_master():
    folder = "å•†å“ç”»åƒURLãƒã‚¹ã‚¿"
    paths = glob.glob(os.path.join(folder, "*.csv"))

    if not paths:
        return {}

    dfs = []
    for p in paths:
        df = pd.read_csv(p, encoding="cp932")
        if (
            "å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰" in df.columns
            and "å•†å“ç”»åƒãƒ‘ã‚¹1" in df.columns
        ):
            dfs.append(df[["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰", "å•†å“ç”»åƒãƒ‘ã‚¹1"]])

    merged = pd.concat(dfs, ignore_index=True)
    merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"] = merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"].astype(str).strip()
    merged["å•†å“ç”»åƒãƒ‘ã‚¹1"] = merged["å•†å“ç”»åƒãƒ‘ã‚¹1"].astype(str).strip()

    return dict(zip(merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"], merged["å•†å“ç”»åƒãƒ‘ã‚¹1"]))


# ==========================
# HTML ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
# ==========================
def make_html_table(df):
    thead = "<thead><tr>" + "".join(
        f"<th>{html.escape(str(c))}</th>" for c in df.columns
    ) + "</tr></thead>"

    body_rows = []
    for _, row in df.iterrows():
        tds = []
        for col in df.columns:
            val = row[col]
            if col == "å•†å“ã‚³ãƒ¼ãƒ‰":
                code = html.escape(str(val))
                tds.append(
                    f"<td><a href='?sku={code}' style='color:#0073e6; text-decoration:none;'>{code}</a></td>"
                )
            elif col == "ç”»åƒ":
                tds.append(f"<td>{val}</td>")
            else:
                tds.append(f"<td>{html.escape(str(val))}</td>")
        body_rows.append("<tr>" + "".join(tds) + "</tr>")

    return f"""
    <table class="sku-table">
        {thead}<tbody>{"".join(body_rows)}</tbody>
    </table>
    """


# ==========================
# Main
# ==========================
def main():
    st.set_page_config(page_title="Tempostar å£²ä¸Šé›†è¨ˆ", layout="wide")
    st.title("Tempostar åœ¨åº«å¤‰å‹•ãƒ‡ãƒ¼ã‚¿ - SKUé›†è¨ˆ")

    # CSVå–å¾—
    raw_paths = sorted(glob.glob("tempostar_stock_*.csv"))
    if not raw_paths:
        st.error("tempostar_stock_*.csv ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    file_infos = []
    pat = re.compile(r"tempostar_stock_(\d{8})")
    for path in raw_paths:
        m = pat.search(os.path.basename(path))
        if m:
            d = datetime.strptime(m.group(1), "%Y%m%d").date()
            file_infos.append({"date": d, "path": path})

    all_dates = sorted({fi["date"] for fi in file_infos})
    min_date, max_date = min(all_dates), max(all_dates)
    years = sorted({d.year for d in all_dates})

    # åˆæœŸå€¤
    one_month_ago = max_date - pd.DateOffset(months=1)
    one_month_ago = max(min_date, one_month_ago.date())

    if "filters" not in st.session_state:
        st.session_state["filters"] = {
            "start_date": one_month_ago,
            "end_date": max_date,
            "keyword": "",
            "min_total_sales": 0,
            "target_days": 30,
            "submitted": False,
        }

    f = st.session_state["filters"]

    # ==========================
    # Sidebar
    # ==========================
    with st.sidebar:
        st.header("é›†è¨ˆæ¡ä»¶")
        st.caption(f"ğŸ“…ãƒ‡ãƒ¼ã‚¿æœŸé–“ï¼š{min_date} ï½ {max_date}")

        with st.form("filter_form"):
            # æ—¥ä»˜å…¥åŠ›
            y1, m1, d1 = st.columns(3)
            s_y = y1.selectbox("é–‹å§‹å¹´", years, index=years.index(f["start_date"].year))
            s_m = m1.selectbox("é–‹å§‹æœˆ", sorted({d.month for d in all_dates}), index=f["start_date"].month-1)
            s_d = d1.selectbox("é–‹å§‹æ—¥", sorted({d.day for d in all_dates}), index=0)

            y2, m2, d2 = st.columns(3)
            e_y = y2.selectbox("çµ‚äº†å¹´", years, index=years.index(f["end_date"].year))
            e_m = m2.selectbox("çµ‚äº†æœˆ", sorted({d.month for d in all_dates}), index=f["end_date"].month-1)
            e_d = d2.selectbox("çµ‚äº†æ—¥", sorted({d.day for d in all_dates}), index=len(sorted({d.day for d in all_dates}))-1)

            keyword = st.text_input("æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰", f["keyword"])
            min_total = st.number_input("å£²ä¸Šå€‹æ•°ä¸‹é™", 0, value=f["min_total_sales"])
            target_days = st.number_input("å®‰å…¨åœ¨åº«ï¼ˆæ—¥æ•°ï¼‰", 1, 365, value=f["target_days"])
            submitted = st.form_submit_button("ã“ã®æ¡ä»¶ã§è¡¨ç¤º")

        if submitted:
            f.update({
                "start_date": date(s_y, s_m, s_d),
                "end_date": date(e_y, e_m, e_d),
                "keyword": keyword,
                "min_total_sales": min_total,
                "target_days": target_days,
                "submitted": True,
            })

    if not f["submitted"]:
        st.info("æ¡ä»¶ã‚’è¨­å®šã—ã¦ã€ã“ã®æ¡ä»¶ã§è¡¨ç¤ºã€ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        return

    start_date, end_date = f["start_date"], f["end_date"]
    keyword, min_total_sales, target_days = f["keyword"], f["min_total_sales"], f["target_days"]

    paths = [fi["path"] for fi in file_infos if start_date <= fi["date"] <= end_date]
    df = load_tempostar_data(paths)

    # ==========================
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµã‚Šè¾¼ã¿ä»–
    # ==========================
    if keyword:
        cond = False
        for c in ["å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“å"]:
            cond |= df[c].astype(str).str.contains(keyword)
        df = df[cond]

    df_sales = df[df["æ›´æ–°ç†ç”±"] == "å—æ³¨å–è¾¼"] if "æ›´æ–°ç†ç”±" in df else df
    agg = df_sales.groupby("å•†å“ã‚³ãƒ¼ãƒ‰")["å¢—æ¸›å€¤"].sum()
    tbl = pd.DataFrame({
        "å•†å“ã‚³ãƒ¼ãƒ‰": agg.index,
        "å£²ä¸Šå€‹æ•°åˆè¨ˆ": -agg.values,
    })
    # æœ€æ–°åœ¨åº«
    stock = df.groupby("å•†å“ã‚³ãƒ¼ãƒ‰")["å¤‰å‹•å¾Œ"].last().fillna(0).astype(int)
    tbl["ç¾åœ¨åº«"] = stock.reindex(tbl["å•†å“ã‚³ãƒ¼ãƒ‰"]).fillna(0).astype(int)

    # å•†å“æƒ…å ±ä»˜ä¸
    info_cols = ["å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰", "å•†å“å", "å±æ€§1å", "å±æ€§2å"]
    info = df_sales.groupby("å•†å“ã‚³ãƒ¼ãƒ‰")[info_cols].last()
    merged = tbl.merge(info, on="å•†å“ã‚³ãƒ¼ãƒ‰", how="left")
    merged = merged[merged["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] >= min_total_sales]

    # ç”»åƒåˆ—ä»˜ä¸
    img_master = load_image_master()
    base_url = "https://image.rakuten.co.jp/hype/cabinet"
    merged.insert(0, "ç”»åƒ", merged["å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰"].apply(lambda c: f'<img src="{base_url + img_master.get(str(c), "")}" width="70">'))

    display = [
        "ç”»åƒ", "å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰",
        "å•†å“å", "å±æ€§1å", "å±æ€§2å",
        "å£²ä¸Šå€‹æ•°åˆè¨ˆ", "ç¾åœ¨åº«"
    ]

    df_view = merged[display].sort_values("å£²ä¸Šå€‹æ•°åˆè¨ˆ", ascending=False)

    # ==========================
    # CSSï¼ˆåˆ—å¹…ï¼†3è¡Œåˆ¶é™ï¼‰
    # ==========================
    st.markdown("""
<style>
.sku-table { border-collapse:collapse; font-size:13px; width:100%; }
.sku-table th { background:#f2f2f2; }
.sku-table td, .sku-table th { padding:4px 6px; border:1px solid #ccc; vertical-align:top; }
.sku-table tbody tr:hover { background:#fafafa; }
.sku-table img { max-height:70px; width:auto; display:block; margin:auto; }

/* ç”»åƒ */
.sku-table td:nth-child(1), .sku-table th:nth-child(1) {
    width:72px; text-align:center;
}
/* å•†å“ã‚³ãƒ¼ãƒ‰/åŸºæœ¬ã‚³ãƒ¼ãƒ‰ */
.sku-table td:nth-child(2), .sku-table th:nth-child(2),
.sku-table td:nth-child(3), .sku-table th:nth-child(3) {
    width:110px; white-space:nowrap;
}
/* å•†å“åï¼ˆæ¨ªåºƒãï¼‹3è¡Œåˆ¶é™ï¼‰ */
.sku-table td:nth-child(4), .sku-table th:nth-child(4) {
    max-width:420px;
    display:-webkit-box;
    -webkit-line-clamp:3;
    -webkit-box-orient:vertical;
    overflow:hidden;
}
/* å±æ€§ */
.sku-table td:nth-child(5), .sku-table th:nth-child(5),
.sku-table td:nth-child(6), .sku-table th:nth-child(6) {
    width:110px; white-space:nowrap;
}
/* æ•°å€¤åˆ— */
.sku-table td:nth-child(7), .sku-table th:nth-child(7),
.sku-table td:nth-child(8), .sku-table th:nth-child(8) {
    width:80px; text-align:right; white-space:nowrap;
}

/* Sticky header */
.sku-table thead th {
    position:sticky;
    top:3.2rem;
    z-index:2;
    background:#f2f2f2;
}
</style>
""", unsafe_allow_html=True)

    # ==========================
    # ã‚¿ãƒ–è¡¨ç¤º
    # ==========================
    tab1, tab2 = st.tabs(["SKUåˆ¥å£²ä¸Šé›†è¨ˆ", "åœ¨åº«å°‘å•†å“ï¼ˆç™ºæ³¨ç›®å®‰ï¼‰"])

    with tab1:
        st.write(f"ğŸ“¦ SKUæ•°:{len(df_view)} ï½œ {start_date}ã€œ{end_date}")
        st.markdown(make_html_table(df_view), unsafe_allow_html=True)

    with tab2:
        days = max((end_date-start_date).days+1, 1)
        restock = merged.copy()
        restock["1æ—¥å¹³å‡å£²ä¸Š"] = (restock["å£²ä¸Šå€‹æ•°åˆè¨ˆ"]/days).round(2)
        restock["ç›®æ¨™åœ¨åº«"] = (restock["1æ—¥å¹³å‡å£²ä¸Š"]*target_days).round()
        restock["ç™ºæ³¨æ¨å¥¨æ•°"] = (restock["ç›®æ¨™åœ¨åº«"]-restock["ç¾åœ¨åº«"]).apply(lambda x:max(int(x),0))
        restock = restock[restock["ç™ºæ³¨æ¨å¥¨æ•°"]>0]
        restock = restock.sort_values("ç™ºæ³¨æ¨å¥¨æ•°",ascending=False)

        if restock.empty:
            st.success("ç™ºæ³¨æ¨å¥¨å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ï¼")
        else:
            cols2 = display + ["1æ—¥å¹³å‡å£²ä¸Š","ç›®æ¨™åœ¨åº«","ç™ºæ³¨æ¨å¥¨æ•°"]
            st.markdown(make_html_table(restock[cols2]), unsafe_allow_html=True)


if __name__ == "__main__":
    main()

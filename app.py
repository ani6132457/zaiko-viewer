import streamlit as st
import pandas as pd
import glob
import os
import html
import re
from datetime import datetime, date, timedelta


# ==========================
# Tempostar CSV èª­ã¿è¾¼ã¿
# ==========================
@st.cache_data
def load_tempostar_data(file_paths):
    dfs = []
    for path in file_paths:
        df = pd.read_csv(path, encoding="cp932")
        df["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"] = os.path.basename(path)
        dfs.append(df)

    all_df = pd.concat(dfs, ignore_index=True)

    # æ•°å€¤åˆ—ã‚’æ˜ç¤ºçš„ã«å¤‰æ›
    for col in ["å¢—æ¸›å€¤", "å¤‰å‹•å¾Œ"]:
        if col in all_df.columns:
            all_df[col] = (
                pd.to_numeric(all_df[col], errors="coerce")
                .fillna(0)
                .astype(int)
            )
    return all_df


# ==========================
# å•†å“ç”»åƒãƒã‚¹ã‚¿èª­ã¿è¾¼ã¿
# ==========================
@st.cache_data
def load_image_master():
    folder = "å•†å“ç”»åƒURLãƒã‚¹ã‚¿"
    paths = glob.glob(os.path.join(folder, "*.csv"))

    if not paths:
        return {}

    dfs = []
    for p in paths:
        df = pd.read_csv(p, encoding="cp932")
        if (
            "å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰" in df.columns
            and "å•†å“ç”»åƒãƒ‘ã‚¹1" in df.columns
        ):
            dfs.append(df[["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰", "å•†å“ç”»åƒãƒ‘ã‚¹1"]])

    if not dfs:
        return {}

    merged = pd.concat(dfs, ignore_index=True)
    merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"] = (
        merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"].astype(str).str.strip()
    )
    merged["å•†å“ç”»åƒãƒ‘ã‚¹1"] = merged["å•†å“ç”»åƒãƒ‘ã‚¹1"].astype(str).str.strip()

    return dict(zip(merged["å•†å“ç®¡ç†ç•ªå·ï¼ˆå•†å“URLï¼‰"], merged["å•†å“ç”»åƒãƒ‘ã‚¹1"]))


# ==========================
# HTML ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯å¯¾å¿œï¼‰
# ==========================
def make_html_table(df):
    thead = "<thead><tr>" + "".join(
        f"<th>{html.escape(str(c))}</th>" for c in df.columns
    ) + "</tr></thead>"

    body_rows = []
    for _, row in df.iterrows():
        tds = []
        for col in df.columns:
            val = row[col]
            if col == "å•†å“ã‚³ãƒ¼ãƒ‰":
                code = html.escape(str(val))
                link = (
                    f"<a href='?sku={code}' "
                    f"style='color:#0073e6; text-decoration:none;'>{code}</a>"
                )
                tds.append(f"<td>{link}</td>")
            elif col == "ç”»åƒ":
                tds.append(f"<td>{val}</td>")
            else:
                tds.append(f"<td>{html.escape(str(val))}</td>")
        body_rows.append("<tr>" + "".join(tds) + "</tr>")

    return f"""
    <table class="sku-table">
      {thead}
      <tbody>{"".join(body_rows)}</tbody>
    </table>
    """


# ==========================
# Main
# ==========================
def main():
    st.set_page_config(page_title="Tempostar å£²ä¸Šé›†è¨ˆ", layout="wide")
    st.title("Tempostar åœ¨åº«å¤‰å‹•ãƒ‡ãƒ¼ã‚¿ - SKUåˆ¥é›†è¨ˆ")

    # ---------- CSV ä¸€è¦§ ----------
    raw_paths = sorted(glob.glob("tempostar_stock_*.csv"))
    if not raw_paths:
        st.error("tempostar_stock_*.csv ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    file_infos = []
    pat = re.compile(r"tempostar_stock_(\d{8})")

    for path in raw_paths:
        name = os.path.basename(path)
        m = pat.search(name)
        if m:
            d = datetime.strptime(m.group(1), "%Y%m%d").date()
            file_infos.append({"date": d, "path": path, "name": name})

    if not file_infos:
        st.error("tempostar_stock_YYYYMMDD.csv å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    all_dates = sorted({fi["date"] for fi in file_infos})
    min_date, max_date = min(all_dates), max(all_dates)

    # ---------- ãƒ•ã‚£ãƒ«ã‚¿åˆæœŸå€¤ ----------
    default_start = max_date - timedelta(days=30)
    if default_start < min_date:
        default_start = min_date

    if "filters" not in st.session_state:
        st.session_state["filters"] = {
            "start_date": default_start,
            "end_date": max_date,
            "keyword": "",
            "min_total_sales": 0,
            "target_days": 30,
            "restock_months": 1,   # åœ¨åº«å°‘ã‚¿ãƒ–ç”¨ï¼šç›´è¿‘â—¯ãƒ¶æœˆ
            "submitted": False,
        }

    f = st.session_state["filters"]

    # ==========================
    # Sidebarï¼ˆãƒ•ã‚©ãƒ¼ãƒ ï¼‹ãƒœã‚¿ãƒ³ï¼‰
    # ==========================
    with st.sidebar:
        st.header("é›†è¨ˆæ¡ä»¶")
        st.caption(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“ï¼š{min_date} ï½ {max_date}")

        with st.form("filter_form"):
            start_date = st.date_input(
                "é–‹å§‹æ—¥", f["start_date"], min_value=min_date, max_value=max_date
            )
            end_date = st.date_input(
                "çµ‚äº†æ—¥", f["end_date"], min_value=min_date, max_value=max_date
            )

            keyword = st.text_input(
                "æ¤œç´¢ï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰ / å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰ / å•†å“åï¼‰",
                f["keyword"],
            )
            min_total_sales = st.number_input(
                "å£²ä¸Šå€‹æ•°ã®ä¸‹é™ï¼ˆãƒ—ãƒ©ã‚¹å€¤ï¼‰",
                min_value=0,
                value=int(f["min_total_sales"]),
            )
            target_days = st.number_input(
                "ä½•æ—¥åˆ†ã®åœ¨åº«ã‚’ç¢ºä¿ã™ã‚‹ã‹ï¼ˆç™ºæ³¨ç›®å®‰ï¼‰",
                min_value=1,
                max_value=365,
                value=int(f["target_days"]),
            )
            restock_months = st.selectbox(
                "åœ¨åº«å°‘å•†å“ã®é›†è¨ˆæœŸé–“ï¼ˆç›´è¿‘â—¯ãƒ¶æœˆï¼‰",
                [1, 2, 3, 4, 5, 6],
                index=[1, 2, 3, 4, 5, 6].index(int(f["restock_months"])),
            )

            submitted = st.form_submit_button("ã“ã®æ¡ä»¶ã§è¡¨ç¤º")

        if submitted:
            if start_date > end_date:
                start_date, end_date = end_date, start_date

            f["start_date"] = start_date
            f["end_date"] = end_date
            f["keyword"] = keyword
            f["min_total_sales"] = int(min_total_sales)
            f["target_days"] = int(target_days)
            f["restock_months"] = int(restock_months)
            f["submitted"] = True

        # å¯¾è±¡CSVä¸€è¦§
        if f["submitted"]:
            target_files = [
                fi
                for fi in file_infos
                if f["start_date"] <= fi["date"] <= f["end_date"]
            ]
            st.markdown("---")
            st.caption("å¯¾è±¡CSVï¼š")
            for fi in target_files:
                st.caption(f"ãƒ»{fi['date']} : {fi['name']}")

    if not f["submitted"]:
        st.info("å·¦ã®æ¡ä»¶ã‚’è¨­å®šã—ã¦ã€ã“ã®æ¡ä»¶ã§è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        return

    start_date = f["start_date"]
    end_date = f["end_date"]
    keyword = f["keyword"]
    min_total_sales = f["min_total_sales"]
    target_days = f["target_days"]
    restock_months = f["restock_months"]

    # ---------- æœŸé–“å†… CSV æŠ½å‡ºï¼ˆSKUé›†è¨ˆç”¨ï¼‰ ----------
    target_files = [fi for fi in file_infos if start_date <= fi["date"] <= end_date]
    if not target_files:
        st.error("é¸æŠç¯„å›²ã®CSVãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    paths = [fi["path"] for fi in target_files]

    # ==========================
    # ãƒ¡ã‚¤ãƒ³DF èª­ã¿è¾¼ã¿
    # ==========================
    df = load_tempostar_data(paths)

    # å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜åˆ—ï¼ˆ_file_dateï¼‰ã‚’ä½œæˆï¼ˆåœ¨åº«å°‘ã‚¿ãƒ–ç”¨ï¼‰
    if "_file_date" not in df.columns:
        date_str = df["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"].str.extract(r"(\d{8})")[0]
        df["_file_date"] = pd.to_datetime(
            date_str, format="%Y%m%d", errors="coerce"
        ).dt.date

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµã‚Šè¾¼ã¿
    if keyword:
        cond = False
        for col in ["å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰", "å•†å“å"]:
            if col in df.columns:
                cond |= df[col].astype(str).str.contains(keyword, case=False)
        df = df[cond]

    # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
    required = {"å•†å“ã‚³ãƒ¼ãƒ‰", "å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰", "å¢—æ¸›å€¤"}
    if not required.issubset(df.columns):
        st.error("Tempostar CSV ã«ã€å•†å“ã‚³ãƒ¼ãƒ‰ã€ã€å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰ã€ã€å¢—æ¸›å€¤ã€ãŒå¿…è¦ã§ã™ã€‚")
        return

    # ==========================
    # å•†å“ã‚³ãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯æ™‚ã®åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•
    # ==========================
    params = st.experimental_get_query_params()
    selected_sku = params.get("sku", [None])[0]

    if selected_sku:
        st.markdown(f"## ğŸ“ˆ åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•ï¼š{selected_sku}")

        if "å¤‰å‹•å¾Œ" not in df.columns:
            st.warning("ã€å¤‰å‹•å¾Œã€åˆ—ãŒãªã„ãŸã‚åœ¨åº«æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
        else:
            df_sku = df[df["å•†å“ã‚³ãƒ¼ãƒ‰"] == selected_sku].copy()
            df_sku["æ—¥ä»˜"] = df_sku["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"].str.extract(r"(\d{8})")
            df_sku["æ—¥ä»˜"] = pd.to_datetime(
                df_sku["æ—¥ä»˜"], format="%Y%m%d", errors="coerce"
            )
            df_plot = df_sku[["æ—¥ä»˜", "å¤‰å‹•å¾Œ"]].dropna().sort_values("æ—¥ä»˜")

            if df_plot.empty:
                st.warning("é¸æŠã—ãŸSKUã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.line_chart(df_plot.set_index("æ—¥ä»˜")["å¤‰å‹•å¾Œ"])

        st.markdown("---")

    # ==========================
    # å£²ä¸Šé›†è¨ˆï¼ˆSKUåˆ¥ã‚¿ãƒ–ç”¨ï¼šã‚µã‚¤ãƒ‰ãƒãƒ¼æ—¥ä»˜ç¯„å›²ï¼‰
    # ==========================
    if "æ›´æ–°ç†ç”±" in df.columns:
        df_sales_all = df[df["æ›´æ–°ç†ç”±"] == "å—æ³¨å–è¾¼"].copy()
    else:
        df_sales_all = df.copy()

    agg_sales = {
        "å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰": "last",
        "å•†å“å": "last",
        "å±æ€§1å": "last",
        "å±æ€§2å": "last",
        "å¢—æ¸›å€¤": "sum",
    }

    sales_grouped = (
        df_sales_all.groupby("å•†å“ã‚³ãƒ¼ãƒ‰", dropna=False)
        .agg(agg_sales)
        .reset_index()
        .rename(columns={"å¢—æ¸›å€¤": "å¢—æ¸›å€¤åˆè¨ˆ"})
    )

    sales_grouped["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] = -sales_grouped["å¢—æ¸›å€¤åˆè¨ˆ"]
    sales_grouped = sales_grouped[sales_grouped["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] > 0]

    # åœ¨åº«ï¼ˆç¾åœ¨åº«ï¼‰â€»å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€æ–°åœ¨åº«ã‚’å–å¾—
    if "å¤‰å‹•å¾Œ" in df.columns:
        stock_group = (
            df.groupby("å•†å“ã‚³ãƒ¼ãƒ‰", dropna=False)["å¤‰å‹•å¾Œ"]
            .last()
            .reset_index()
            .rename(columns={"å¤‰å‹•å¾Œ": "ç¾åœ¨åº«"})
        )
        stock_group["ç¾åœ¨åº«"] = (
            pd.to_numeric(stock_group["ç¾åœ¨åº«"], errors="coerce")
            .fillna(0)
            .astype(int)
        )
        sales_grouped = sales_grouped.merge(stock_group, on="å•†å“ã‚³ãƒ¼ãƒ‰", how="left")
    else:
        sales_grouped["ç¾åœ¨åº«"] = 0

    sales_grouped["ç¾åœ¨åº«"] = (
        pd.to_numeric(sales_grouped["ç¾åœ¨åº«"], errors="coerce")
        .fillna(0)
        .astype(int)
    )

    # å£²ä¸Šå€‹æ•°ã®ä¸‹é™ãƒ•ã‚£ãƒ«ã‚¿
    if min_total_sales > 0:
        sales_grouped = sales_grouped[
            sales_grouped["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] >= min_total_sales
        ]

    sales_grouped = sales_grouped.sort_values("å£²ä¸Šå€‹æ•°åˆè¨ˆ", ascending=False)

    # ==========================
    # ç”»åƒåˆ—ã®ä»˜ä¸ï¼ˆå…±é€šï¼‰
    # ==========================
    img_master = load_image_master()
    base_url = "https://image.rakuten.co.jp/hype/cabinet"

    def to_img(code):
        key = str(code).strip()
        rel = img_master.get(key, "")
        if not rel:
            return ""
        return f'<img src="{base_url + rel}" width="70">'

    sales_grouped["ç”»åƒ"] = sales_grouped["å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰"].apply(to_img)

    # ç”»åƒåˆ—ã‚’å…ˆé ­ã¸
    cols = sales_grouped.columns.tolist()
    cols.insert(0, cols.pop(cols.index("ç”»åƒ")))
    sales_grouped = sales_grouped[cols]

    display_cols = [
        "ç”»åƒ",
        "å•†å“ã‚³ãƒ¼ãƒ‰",
        "å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰",
        "å•†å“å",
        "å±æ€§1å",
        "å±æ€§2å",
        "å£²ä¸Šå€‹æ•°åˆè¨ˆ",
        "ç¾åœ¨åº«",
        "å¢—æ¸›å€¤åˆè¨ˆ",
    ]
    df_view = sales_grouped[display_cols]

    # ==========================
    # CSSï¼ˆåˆ—å¹…ãƒ»3è¡Œåˆ¶é™ãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®šï¼‰
    # ==========================
    st.markdown(
        """
<style>
.sku-table { border-collapse:collapse; font-size:13px; width:100%; }
.sku-table th { background:#f2f2f2; }
.sku-table td, .sku-table th {
    padding:4px 6px;
    border:1px solid #ccc;
    vertical-align:top;
}
.sku-table tbody tr:hover { background:#fafafa; }
.sku-table img { max-height:70px; width:auto; display:block; margin:auto; }

/* 1:ç”»åƒ */
.sku-table td:nth-child(1), .sku-table th:nth-child(1) {
    width:72px; text-align:center;
}
/* 2,3:ã‚³ãƒ¼ãƒ‰ */
.sku-table td:nth-child(2), .sku-table th:nth-child(2),
.sku-table td:nth-child(3), .sku-table th:nth-child(3) {
    width:110px; white-space:nowrap;
}
/* 4:å•†å“å */
/* ãƒ˜ãƒƒãƒ€ãƒ¼ã¯æ™®é€šã®ã¾ã¾ */
.sku-table th:nth-child(4) {
    max-width:420px;
}
/* ãƒ‡ãƒ¼ã‚¿å´ã ã‘3è¡Œåˆ¶é™ */
.sku-table td:nth-child(4) {
    max-width:420px;
    display:-webkit-box;
    -webkit-line-clamp:3;
    -webkit-box-orient:vertical;
    overflow:hidden;
}
/* 5,6:å±æ€§ */
.sku-table td:nth-child(5), .sku-table th:nth-child(5),
.sku-table td:nth-child(6), .sku-table th:nth-child(6) {
    width:110px; white-space:nowrap;
}
/* 7,8,9:æ•°å€¤åˆ— */
.sku-table td:nth-child(7), .sku-table th:nth-child(7),
.sku-table td:nth-child(8), .sku-table th:nth-child(8),
.sku-table td:nth-child(9), .sku-table th:nth-child(9) {
    width:80px; text-align:right; white-space:nowrap;
}

/* ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®š */
.sku-table thead th {
    position:sticky;
    top:3.2rem;
    z-index:2;
    background:#f2f2f2;
}
</style>
""",
        unsafe_allow_html=True,
    )

    # ==========================
    # ã‚¿ãƒ–è¡¨ç¤º
    # ==========================
    tab1, tab2 = st.tabs(["SKUåˆ¥å£²ä¸Šé›†è¨ˆ", "åœ¨åº«å°‘å•†å“ï¼ˆç™ºæ³¨ç›®å®‰ï¼‰"])

    # ---- ã‚¿ãƒ–1ï¼šSKUåˆ¥å£²ä¸Šé›†è¨ˆï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æœŸé–“ï¼‰----
    with tab1:
        st.write(
            f"ğŸ“¦ SKUæ•°ï¼š{len(df_view):,} ï½œ é›†è¨ˆæœŸé–“ï¼š{start_date} ï½ {end_date}"
        )
        st.markdown(make_html_table(df_view), unsafe_allow_html=True)

    # ---- ã‚¿ãƒ–2ï¼šåœ¨åº«å°‘å•†å“ï¼ˆç›´è¿‘â—¯ãƒ¶æœˆï¼‰----
    with tab2:
        # ç›´è¿‘ restock_months ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã§å£²ä¸Šã‚’å†é›†è¨ˆ
        end_r = max_date
        start_r = (pd.Timestamp(max_date) - pd.DateOffset(months=restock_months)).date()
        if start_r < min_date:
            start_r = min_date

        period_days = max((end_r - start_r).days + 1, 1)

        df_recent = df[(df["_file_date"] >= start_r) & (df["_file_date"] <= end_r)]

        if df_recent.empty:
            st.warning(
                f"ç›´è¿‘{restock_months}ãƒ¶æœˆï¼ˆ{start_r} ï½ {end_r}ï¼‰ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
            )
        else:
            if "æ›´æ–°ç†ç”±" in df_recent.columns:
                df_sales_recent = df_recent[df_recent["æ›´æ–°ç†ç”±"] == "å—æ³¨å–è¾¼"].copy()
            else:
                df_sales_recent = df_recent.copy()

            if df_sales_recent.empty:
                st.warning(
                    f"ç›´è¿‘{restock_months}ãƒ¶æœˆï¼ˆ{start_r} ï½ {end_r}ï¼‰ã«å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
                )
            else:
                sales_recent = (
                    df_sales_recent.groupby("å•†å“ã‚³ãƒ¼ãƒ‰", dropna=False)
                    .agg(agg_sales)
                    .reset_index()
                    .rename(columns={"å¢—æ¸›å€¤": "å¢—æ¸›å€¤åˆè¨ˆ"})
                )
                sales_recent["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] = -sales_recent["å¢—æ¸›å€¤åˆè¨ˆ"]
                sales_recent = sales_recent[sales_recent["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] > 0]

                # æœ€æ–°åœ¨åº«ï¼ˆstock_groupï¼‰ã‚’ãƒãƒ¼ã‚¸
                if "ç¾åœ¨åº«" in sales_grouped.columns:
                    stock_for_merge = sales_grouped[["å•†å“ã‚³ãƒ¼ãƒ‰", "ç¾åœ¨åº«"]].copy()
                    sales_recent = sales_recent.merge(
                        stock_for_merge, on="å•†å“ã‚³ãƒ¼ãƒ‰", how="left"
                    )
                else:
                    sales_recent["ç¾åœ¨åº«"] = 0

                sales_recent["ç¾åœ¨åº«"] = (
                    pd.to_numeric(sales_recent["ç¾åœ¨åº«"], errors="coerce")
                    .fillna(0)
                    .astype(int)
                )

                # ç”»åƒåˆ—
                sales_recent["ç”»åƒ"] = sales_recent["å•†å“åŸºæœ¬ã‚³ãƒ¼ãƒ‰"].apply(to_img)

                # è¡¨ç¤ºé †ã«æƒãˆã‚‹
                cols_r = ["ç”»åƒ"] + [c for c in display_cols if c != "ç”»åƒ"]
                sales_recent = sales_recent[cols_r]

                # 1æ—¥å¹³å‡å£²ä¸Šãƒ»ç›®æ¨™åœ¨åº«ãƒ»ç™ºæ³¨æ¨å¥¨æ•°
                sales_recent["1æ—¥å¹³å‡å£²ä¸Š"] = (
                    sales_recent["å£²ä¸Šå€‹æ•°åˆè¨ˆ"] / period_days
                )
                sales_recent["ç›®æ¨™åœ¨åº«"] = (
                    sales_recent["1æ—¥å¹³å‡å£²ä¸Š"] * target_days
                )

                target_qty = pd.to_numeric(
                    sales_recent["ç›®æ¨™åœ¨åº«"], errors="coerce"
                )
                current_stock = pd.to_numeric(
                    sales_recent["ç¾åœ¨åº«"], errors="coerce"
                )
                diff = (target_qty - current_stock).fillna(0)
                sales_recent["ç™ºæ³¨æ¨å¥¨æ•°"] = (
                    diff.where(diff > 0, 0).round().astype(int)
                )

                restock_view = sales_recent[sales_recent["ç™ºæ³¨æ¨å¥¨æ•°"] > 0]
                restock_view = restock_view.sort_values(
                    "ç™ºæ³¨æ¨å¥¨æ•°", ascending=False
                )

                st.info(
                    f"ç™ºæ³¨ç›®å®‰ã¯ç›´è¿‘{restock_months}ãƒ¶æœˆï¼ˆ{start_r} ï½ {end_r}ï¼‰ã®å£²ä¸Šã‹ã‚‰è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚"
                )

                if restock_view.empty:
                    st.success("ç™ºæ³¨æ¨å¥¨ã®å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    cols2 = display_cols + ["1æ—¥å¹³å‡å£²ä¸Š", "ç›®æ¨™åœ¨åº«", "ç™ºæ³¨æ¨å¥¨æ•°"]
                    restock_view = restock_view[cols2]
                    st.write(
                        f"âš  æŠ½å‡ºSKUæ•°ï¼š{len(restock_view):,} ï½œ ç›®æ¨™åœ¨åº«ï¼šå¹³å‡ {target_days} æ—¥åˆ†"
                    )
                    st.markdown(
                        make_html_table(restock_view),
                        unsafe_allow_html=True,
                    )


if __name__ == "__main__":
    main()
